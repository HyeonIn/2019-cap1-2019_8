{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "import os\n",
    "import zipfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict()\n",
    "for path in glob.glob(r\"D:\\capstone\\word\\data\\docx\\*.csv\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        next(iter(f))\n",
    "\n",
    "        for line in f.readlines():\n",
    "            md5, label = line.strip().split(\",\")\n",
    "\n",
    "            label_dict[md5] = int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_OF_DF_VECTOR = 4096\n",
    "\n",
    "def create_file_list(PATH):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(PATH):\n",
    "        for file in files:\n",
    "            if file.split(\".\")[-1] != \"csv\":\n",
    "                file_list.append(os.path.join(root, file))\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def set_count(file_list):\n",
    "    m_set = set()\n",
    "    for i in file_list:\n",
    "        try:\n",
    "            # document will be the filetype zipfile.ZipFile\n",
    "            document = zipfile.ZipFile(i)\n",
    "            name_list = document.namelist()\n",
    "            for i in name_list:\n",
    "                items = i.split('/')\n",
    "                for i in range(0, len(items)):\n",
    "                    m_set.add('/'.join(items[i:]))\n",
    "        except zipfile.BadZipfile:\n",
    "            continue\n",
    "    return m_set\n",
    "\n",
    "\n",
    "def make_table(file_list):\n",
    "    df_dict = {}\n",
    "    for i in tqdm(file_list):\n",
    "        try:\n",
    "            document = zipfile.ZipFile(i)\n",
    "            name_list = document.namelist()\n",
    "\n",
    "            for i in name_list:\n",
    "                items = i.split('/')\n",
    "                for i in range(0, len(items)):\n",
    "                    df_dict['/'.join(items[i:])] = df_dict.get('/'.join(items[i:]), 0) + 1\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    df_rank_list = sorted(df_dict.items(), key=lambda x: x[1], reverse=True)[:SIZE_OF_DF_VECTOR]\n",
    "\n",
    "    df_rank_dict = dict()\n",
    "    rank = 0\n",
    "\n",
    "    for k, _ in df_rank_list:\n",
    "        df_rank_dict[k] = rank\n",
    "        rank += 1\n",
    "\n",
    "    return df_rank_dict\n",
    "\n",
    "\n",
    "def get_entropy(data):\n",
    "    \"\"\"Calculate the entropy of a chunk of data.\"\"\"\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    occurences = collections.Counter(bytearray(data))\n",
    "\n",
    "    entropy = 0\n",
    "    for x in occurences.values():\n",
    "        p_x = float(x) / len(data)\n",
    "        entropy -= p_x * math.log(p_x, 2)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def make_feature_vec(df_rank_dict, file_list, label):\n",
    "    ret_feature = []\n",
    "    ret_label = []\n",
    "    for path in tqdm(file_list):\n",
    "        md5 = os.path.basename(path).split(\".\")[0]\n",
    "        \n",
    "        if md5 in label:\n",
    "            try:\n",
    "                feature_vector = [0 for _ in range(SIZE_OF_DF_VECTOR)]\n",
    "                entropy_list = []\n",
    "                file_size = []\n",
    "\n",
    "\n",
    "                with zipfile.ZipFile(path) as document:\n",
    "                    name_list = document.namelist()\n",
    "\n",
    "                    for name in name_list:\n",
    "                        items = name.split('/')\n",
    "                        for i in range(0, len(items)):\n",
    "                            k = '/'.join(items[i:])\n",
    "                            if k in df_rank_dict:\n",
    "                                feature_vector[df_rank_dict[k]] = 1\n",
    "\n",
    "\n",
    "\n",
    "                    for name in name_list:\n",
    "                        with document.open(name) as f:\n",
    "                            data = f.read()\n",
    "                            entropy_list.append(get_entropy(data))\n",
    "                            file_size.append(len(data))\n",
    "\n",
    "#                 feature_vector += [min(entropy_list), max(entropy_list), np.mean(entropy_list),\n",
    "#                                    os.path.getsize(path), min(file_size), max(file_size), np.mean(file_size)]\n",
    "\n",
    "    #             with open(os.path.join(SAVE_PATH, str(os.path.basename(path).split('.')[0])) + '.pkl', 'wb') as f:\n",
    "    #                 pickle.dump(feature_vector, f)\n",
    "                ret_feature.append(feature_vector)\n",
    "                ret_label.append(label[md5])\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    return ret_feature, ret_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = r'D:\\capstone\\word\\data\\virusign'\n",
    "SAVE_PATH = r''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730e2152f12641759f6ab7f12a4e8a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5457), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_list = create_file_list(r\"D:\\capstone\\word\\data\\docx\")\n",
    "# file_list += create_file_list(r\"D:\\capstone\\word\\data\\virusshare\")\n",
    "# file_list += create_file_list(r\"D:\\capstone\\word\\data\\google_docx\")\n",
    "df_dict = make_table(file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bc6c1cc8414a18bbaea13150373bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5457), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features, label = make_feature_vec(df_dict, file_list, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 64,\n",
    "         'min_data_in_leaf': 64,\n",
    "         'objective':'binary',\n",
    "         'nthread': 1,\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.05,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": ['auc','binary_logloss'],\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"random_state\": 24,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 4882\n"
     ]
    }
   ],
   "source": [
    "mal, ben = 0, 0\n",
    "\n",
    "for i in label:\n",
    "    if i == 1: mal += 1 \n",
    "    else: ben += 1\n",
    "        \n",
    "print(mal, ben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5044"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.889537+0.0299921\ttest-auc:0.871425+0.0624036\n",
      "[10]\ttrain-auc:0.983566+0.00139581\ttest-auc:0.963781+0.0285423\n",
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.889537       0.029992       0.871425      0.062404\n",
      "1        0.953708       0.002435       0.949763      0.029374\n",
      "2        0.968098       0.002167       0.957512      0.025788\n",
      "3        0.973619       0.002328       0.964926      0.025679\n",
      "4        0.978001       0.001782       0.963617      0.029024\n",
      "5        0.979466       0.001373       0.962383      0.031588\n",
      "6        0.980736       0.001152       0.961773      0.033651\n",
      "7        0.981602       0.001315       0.961860      0.033808\n",
      "8        0.982402       0.001253       0.965799      0.027241\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {'eta': 1, \"lambda\":0.7, 'objective': 'binary:logistic', \"metric\":\"auc\", \"silent\":True}\n",
    "\n",
    "trn_data = xgb.DMatrix(np.array(features), label=label)\n",
    "\n",
    "cv_results = xgb.cv(params, trn_data, nfold=10, num_boost_round=100, early_stopping_rounds=5, verbose_eval=10, metrics=\"auc\")\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's auc: 0.923599 + 0.0321902\tcv_agg's binary_logloss: 0.091637 + 0.00928612\n",
      "Best num_boost_round: 82\n",
      "Best CV score: 0.9312730472701753\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "trn_data = lgb.Dataset(np.array(features), label=label)\n",
    "\n",
    "cv_results = lgb.cv(param, trn_data, nfold=10, verbose_eval=50, early_stopping_rounds=10, num_boost_round=500)\n",
    "\n",
    "print('Best num_boost_round:', len(cv_results['auc-mean']))\n",
    "print('Best CV score:', cv_results['auc-mean'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DF 4096 : CV 0.86\n",
    "- DF_new 4096 : CV 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 's mean cv 10-fold is  0.9894880481837005\n",
      "DT 's mean cv 10-fold is  0.988495984691637\n",
      "SVM 's mean cv 10-fold is  0.9678838070142419\n",
      "NB 's mean cv 10-fold is  0.35764869188782233\n",
      "KNN 's mean cv 10-fold is  0.9859228935315892\n",
      "RF 's mean cv 10-fold is  0.989288851245373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "models = []\n",
    "models.append((\"LR\", LogisticRegression()))\n",
    "models.append((\"DT\", DecisionTreeClassifier()))\n",
    "models.append((\"SVM\", SVC()))\n",
    "models.append((\"NB\", GaussianNB()))\n",
    "models.append((\"KNN\", KNeighborsClassifier()))\n",
    "models.append((\"RF\", RandomForestClassifier()))\n",
    "\n",
    "\n",
    "def get_cv(x_train, y_train):\n",
    "    for name, model in models:\n",
    "        scores = np.mean(cross_val_score(model, x_train, y_train, cv=10))\n",
    "        print(name, \"'s mean cv 10-fold is \", scores)\n",
    "\n",
    "get_cv(features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR 's 10-Fold CV Score :  0.9254725526731571  \n",
    "DT 's 10-Fold CV Score :  0.9571000986149965  \n",
    "SVM 's 10-Fold CV Score :  0.9284180185954861  \n",
    "NB 's 10-Fold CV Score :  0.3311396892139982  \n",
    "KNN 's 10-Fold CV Score :  0.9482514568334703  \n",
    "RF 's 10-Fold CV Score :  0.9630061495245068  \n",
    "LightGBM's 10-Fold CV Score : 0.9842461380757872  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR 's 10-fold CV score :0.9195729686998744  \n",
    "DT 's 10-fold CV score : 0.9211851512361253  \n",
    "SVM 's 10-fold CV score : 0.9190360549808281  \n",
    "NB 's 10-fold CV score : 0.6133994340544391  \n",
    "KNN 's 10-fold CV score : 0.9027258945530207  \n",
    "RF 's 10-fold CV score : 0.9201106031084766  \n",
    "LightGBM's 10-fold CV score : 0.8612848846386318  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0]\ttrain-auc:0.938966+0.00847722\ttest-auc:0.930315+0.0351822  \n",
    "[10]\ttrain-auc:1+9e-07\ttest-auc:0.990878+0.0126826  \n",
    "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std  \n",
    "0         0.938966   8.477220e-03       0.930315      0.035182  \n",
    "1         0.972962   3.824079e-03       0.968325      0.035363  \n",
    "2         0.991657   2.781738e-03       0.978689      0.025427  \n",
    "3         0.995503   1.908980e-03       0.983970      0.018244  \n",
    "4         0.998909   8.547105e-04       0.982017      0.019508  \n",
    "5         0.999767   1.469840e-04       0.988409      0.014128  \n",
    "6         0.999948   2.818883e-05       0.988385      0.013744  \n",
    "7         0.999985   1.876939e-05       0.987859      0.016501  \n",
    "8         0.999994   9.293008e-06       0.988979      0.016222  \n",
    "9         0.999998   2.332381e-06       0.989519      0.013905  \n",
    "10        1.000000   9.000000e-07       0.990878      0.012683  \n",
    "11        1.000000   0.000000e+00       0.991216      0.012434  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
